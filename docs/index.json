{"project": "Coffea", "project_url": "https://coffeateam.github.io/coffea/", "show_commit_url": "#", "hash_length": 8, "revision_to_hash": {"2": "16c35ec610b84b15124153e4dc598c317b26cedf", "24": "2a204e5e16f408b605f6c46236869d73d646ad83", "38": "92438b542d10acc96b5db22dda33e7a45df12d72", "121": "b4c9a7aa45eb9d0271c7961fbad3e6f07c379f52", "220": "55229adaef0b7435a9c10f8de925e24e2d69f0ee", "222": "377381605304595557f5cf5e60a27377efa11da4", "228": "a63e2bc5853b3e7ed8c0df5841bbd226ce70e483", "257": "f06a2028e00bbf8096e718b66fca2306262ee6ee", "259": "e2fb4ad7f9f13e120fc2170ab3139f010b14a081", "267": "cebd207d9a2fd74c45975d1a4f918070806ee351", "283": "99e536a3077ce1e9a55a4a02cce006dd99ddfb94", "293": "3a97cdd647cddb648d1984afad6679920a7f97bc", "299": "acfe0174639e143c4cf9164fb97081e4313834a6", "313": "1508b6be6835560d793f4bcce471c998842682e5", "327": "806d298da230b556bc03c9e413f957e273174f61", "376": "7874f0527be3f20160339f1f56fce2930a786cd8", "396": "94da0633582f04fb69db088fccc97f616618bd9d", "400": "e31b98fc5bc23999b50e42543108a5f941f98472", "431": "f4eb01330e4b6c3e491a8ef5d0defdfe598efdb8", "465": "8370c2a6603729685c6c7219c3681b20acca03ef", "495": "04dfdc39df57256cd90bc14553db36e431cee00b", "537": "e3a402c4b72ccc5394c145bacac5db3cc72ede6f", "545": "00ba8150ee53b639269d8bb5ee42c7a468187f2f", "557": "49495e341957f91ec85ae43bea026d1aa5a3480a", "569": "183dffd24e50e5b89cfce05e1bd9134f55148b1b", "577": "de058292bd5b31e644d35c01367d8e3ac03a1420", "585": "ee1ade0564d87fe12835530246445fb67e9b45c4", "603": "c32339a448633e9c8a70b6ce65ee1e4023c4dbb6", "641": "fd20c45c64c442e95c4435fb48f94cb663a9df89", "643": "cc77189a863ff71e9ea894498a7b131a9efb68a7", "647": "42b0f04648c6f3f4ddd6a75d86407baad5e11440", "649": "985c02c1b31e03033ad5de1f60822b6a7127d712", "655": "fef487f3bc26ae956b6a3e2b48ac9c8e40a805be", "659": "c1ee613faf0b0e7a3f2ab826bd1fe3ad7194fc87", "661": "2f52759b9deaee52a20af931675bb76934b9595e", "665": "f923f975efb60c1b2eb350c970b4f0feac17a2c0", "667": "e029d5b85fb1518a87d127de98be36b026346187", "669": "9ed764a54bd35c4fbe36ff6f3d093700c187631d", "671": "522a5ce5ca1fb4e0e9725c592c2f9d403691ead1", "673": "aa24f3b54c26c45aa22eb54f7ad741bc11dddda4", "675": "22dee85a2c607daa0ee5253f590f1e4d04cd8c08", "681": "0f08d46fc83155ff6a726891adf9ffaa2b70888f", "707": "bf0e23c581c916ed6d5a6cf794119623bbf178e4", "709": "2adfec2060a4d6c047168255374e394a08cbbc17", "711": "84c9dad50cccb0b5b5a098ff57c354df9f339880", "728": "d1b9c1f862ae61fe7f9bc86bb9723c45d0faef14", "744": "69f1a00a7341dd3e58dc519373dbda7f20fd6513", "758": "0793ff534d1061b8e5af27c262bf17e0abd4af82", "786": "3f03e74a0cb43da07949c4e480602eb9c32f0329", "830": "9902e4b058d4313bc4f357c18b1de56012c8b445", "832": "0fd121918c98347d2cfbba8537898403e3605a81", "834": "75db7e30c3165966710fe55345de41e5b25fc7d0", "842": "7560c9d13712bbb7ef3840647794667922ed1062", "882": "bbf9b8992fa40786c02cdf8f5cfff982eeef29cf", "905": "636f7d421fca9ac14f4ddf5d23be19089cdaeab4", "938": "41a9440d3257847f982eaa976a0e3e8a9b69a125", "971": "04e33aa8886f5dd9cf0a2513377abddd0071eb3f", "1001": "6a86252e27bd11b7d67647484ebc0ac08cf8fe0c", "1019": "4ab5ac09327f7618e4e8eac036381af7a19e01ea", "1033": "a9fd7d051f3071dde4d5241b2953001e68b9e277", "1042": "4060e54db6c7636281d9d49d8683b4f263bdc564", "1048": "0dd4f1e6809e7731bcecee11827d742aaba52e40", "1053": "da7d16002148a77e5dc05d8fe994e15c5a92b21c", "1064": "acf84901164d95d609773a93f04c5711cf78ef17", "1085": "784380b486110630d63ab05466cccf61da8be21e", "1107": "41dddc1b39698974b94b696eccde880e3ecc80ea", "1117": "ef333022da5c4c02eb10828189a62b424e66728f", "1200": "758975c60e1fe91fa07d406cd61c77eb4918c2c8", "1216": "342755968874a4ca77da1271a90568c390f2c6bb", "1224": "5272fccf1702e6797330687d647e81d2a5299769", "1228": "09b56174937a44ba2555e5905e52d7cc86288f2d", "1234": "26cc66d3dfa18dde282fd466182a653a5f4bfe2f", "1244": "f7ca9381c88c24f38315863f5ad42563cf561885", "1254": "d6c6ad8de518f343b5bc563ce94b9c2b38e3eab0", "1260": "5eda3869f046a30dbebba96cf1fdaaf06a8e7e6d", "1284": "6dabc994be4c544bead45446c524892c9ca8c6a0", "1297": "193cbda4832fdab8dbd3edd189c2301fab95b61e", "1305": "9f4de420688df760c908060e75b8a1de963d4dd9", "1347": "0eaff5c4b8d88a4652b7be85c19c83557660458c", "1375": "90d1a32fa39187596761cb75116f699432dc2d17", "1385": "153cc8d5856a4d2440a48a3982df1cdeb749365a", "1400": "56be7adfc86a0c49aafa2ae51333f326449204ec", "1417": "086b087cf6abca122aca731a49d15d0087e80ba6", "1418": "0fac461e60622544780a0a5cfae0ff7b36912d7e", "1422": "2af9c14c74e62a12122189774ab2a1133edad2fd", "1439": "28da6a5a39c573fa261195c44ed48ed11f4643ad", "1471": "95597bff8a128b4764aecd61448fad55c5f1e18b", "1482": "fb52a8a31245c6f4cf5bbd13ea51cdda5262dfa0", "1492": "d66d9c8e09b008647074b5270bbb022a20fde8cd", "1501": "aff2df213617b1ad3bba0d539158a13fb09e5e20", "1519": "88a4e4269159eaba29e1257b89a74c5d63d5a999", "1546": "b4f8b2176590e5a55d8fe7e7ccf707a414b68359", "1551": "32569909c5bae1091b59c734ce7466ccc3b70618", "1604": "b507830b7df9efae64e296732f4beb6903d8f57b", "1640": "1cb060ef0e213ea87ede7ee9dca440a7c66304ad", "1641": "80d36d3e8f67c2fa82adf950f2f6626f10c85049", "1647": "b4718fa1bad1f5a8b03b8dee1b0ea2fdb141b70e", "1680": "d5126ca0f5ebc00522d4fc453cb7635fb73b3d9c", "1701": "b531e529c64b446efd694917b69dd17e8c087fe1", "1746": "c0c3e4e3bd3f41d9780562a876b49d432a9dd89f", "1774": "a5583401173859878b52dea44b14ed6c613aea81", "1809": "ed135a683de925641da55c4f468e5b8e7746b406", "1843": "ff0310cdfa4025c415ae2e346794c9ed330c7808", "1880": "ad127e6b8ae43d78eb8b4340c6e31026d8ea5257", "1911": "6b17d3cb18969f9cc4dd780f8442bb3b270d57fc", "1928": "24f542f7ce2e638a848c40d1c5905614396a18dd", "2029": "36f4ce75190312443429dc5122ed3c8806c19385", "2032": "7bc67ce1551962cc468c1ba08913097bdcf6ac64", "2087": "05af78bed2d890169842117d7ad647259dc40fa9", "2176": "8c58807e199a7694bf15e3803dbaf706d34bbfa0", "2288": "87197001f7f73af57fee1189123ed575397fb0bb", "2341": "6d548538653e7003281a572f8eec5d68ca57b19f", "2378": "05b87014e64ab376c94dcbb84fb186021a837326", "2456": "ea73fc7cd8b27914845db54f296d9e55740d93cf", "2542": "6defc274b22d813ab1de8c1fc5dc14321f93e9ab", "2606": "e28daae0346675281f3b7b327b5cd190eaa9f721", "2654": "46dfab1df3e6b3b69478bb605ccaf835e93da4bf", "2698": "94909d7ca05c764bb14d298531ee50763a34824b", "2706": "fec5f6458274a0b99705b56dab93071d39f54b3c", "2742": "e08d634cf7d9bd088f49c05d59650998cb1d74bc", "2758": "23b0d2006b5eaede333f45c97dc0c86da633aa91", "2807": "b644bcf2b48e272e6c78e4b1ddee3c233a67022d", "2832": "34c10015e49d402d414bd9432a8f26bdd81cbecb", "2871": "b14672ef969fa0ee0e4ad150936bc6465dbde7bd", "2896": "20a7e749eea3b8de4880088d2f0e43f6ef9d7993"}, "revision_to_date": {"2": 1543503597000, "24": 1543625090000, "38": 1543644847000, "121": 1544812971000, "220": 1546905539000, "222": 1546906181000, "228": 1547062291000, "257": 1549043972000, "259": 1549337644000, "267": 1549392674000, "283": 1549476192000, "293": 1550855919000, "299": 1551281884000, "313": 1552088928000, "327": 1553022107000, "376": 1555055778000, "396": 1555436501000, "400": 1555437132000, "431": 1557529060000, "465": 1557696552000, "495": 1557765852000, "537": 1558011630000, "545": 1558118882000, "557": 1558378325000, "569": 1558714201000, "577": 1558816881000, "585": 1558893967000, "603": 1559156528000, "641": 1559581660000, "643": 1559581889000, "647": 1559584478000, "649": 1559584884000, "655": 1559633709000, "659": 1559634942000, "661": 1559635030000, "665": 1559636269000, "667": 1559636849000, "669": 1559639600000, "671": 1559639975000, "673": 1559640605000, "675": 1559642015000, "681": 1559645792000, "707": 1559842399000, "709": 1559843049000, "711": 1559843891000, "728": 1559932334000, "744": 1559947088000, "758": 1560042245000, "786": 1560139194000, "830": 1560268688000, "832": 1560273080000, "834": 1560344856000, "842": 1560347737000, "882": 1560823239000, "905": 1561443939000, "938": 1561647880000, "971": 1562109004000, "1001": 1562951129000, "1019": 1563387092000, "1033": 1563827908000, "1042": 1564362509000, "1048": 1564758410000, "1053": 1566583476000, "1064": 1568933205000, "1085": 1569426546000, "1107": 1571092509000, "1117": 1571222610000, "1200": 1571923997000, "1216": 1573235230000, "1224": 1573279512000, "1228": 1573479592000, "1234": 1574194406000, "1244": 1574282962000, "1254": 1575342359000, "1260": 1575506094000, "1284": 1576080281000, "1297": 1576173926000, "1305": 1576600258000, "1347": 1576892171000, "1375": 1577902413000, "1385": 1577912773000, "1400": 1578588628000, "1417": 1579282635000, "1418": 1579288906000, "1422": 1579816868000, "1439": 1580328491000, "1471": 1581879206000, "1482": 1582549243000, "1492": 1584030315000, "1501": 1584108405000, "1519": 1585174355000, "1546": 1587400344000, "1551": 1588012595000, "1604": 1592436160000, "1640": 1594648045000, "1641": 1594656826000, "1647": 1594996330000, "1680": 1597881128000, "1701": 1598892251000, "1746": 1600921536000, "1774": 1604609013000, "1809": 1607379603000, "1843": 1608048222000, "1880": 1608338493000, "1911": 1608784167000, "1928": 1609460261000, "2029": 1612209464000, "2032": 1612224678000, "2087": 1613768052000, "2176": 1617401602000, "2288": 1620399426000, "2341": 1622836821000, "2378": 1625252282000, "2456": 1628282970000, "2542": 1630699788000, "2606": 1633130089000, "2654": 1635536512000, "2698": 1638564947000, "2706": 1638818194000, "2742": 1644196787000, "2758": 1646670125000, "2807": 1648835282000, "2832": 1652738071000, "2871": 1656769186000, "2896": 1658853882000}, "params": {"machine": ["FlatIron"], "os": ["Linux 4.18.0-358.el8.x86_64"], "arch": ["x86_64"], "cpu": ["Intel(R) Xeon(R) Gold 6348 CPU @ 2.60GHz"], "num_cpu": ["112"], "ram": ["527526844"], "python": ["3.8"], "cabinetry": [""], "vector": [""], "blosc": [""], "cloudpickle": ["2.0.0"], "distributed": [""], "xrootd": [""], "psutil": [""], "tqdm": [""], "branch": ["master", "34c1001", "b644bcf"]}, "graph_param_list": [{"machine": "FlatIron", "os": "Linux 4.18.0-358.el8.x86_64", "arch": "x86_64", "cpu": "Intel(R) Xeon(R) Gold 6348 CPU @ 2.60GHz", "num_cpu": "112", "ram": "527526844", "python": "3.8", "cabinetry": "", "vector": "", "blosc": "", "cloudpickle": "2.0.0", "distributed": "", "xrootd": "", "psutil": "", "tqdm": "", "branch": "master"}, {"machine": "FlatIron", "os": "Linux 4.18.0-358.el8.x86_64", "arch": "x86_64", "cpu": "Intel(R) Xeon(R) Gold 6348 CPU @ 2.60GHz", "num_cpu": "112", "ram": "527526844", "python": "3.8", "cabinetry": "", "vector": "", "blosc": "", "cloudpickle": "2.0.0", "distributed": "", "xrootd": "", "psutil": "", "tqdm": "", "branch": "34c1001"}, {"machine": "FlatIron", "os": "Linux 4.18.0-358.el8.x86_64", "arch": "x86_64", "cpu": "Intel(R) Xeon(R) Gold 6348 CPU @ 2.60GHz", "num_cpu": "112", "ram": "527526844", "python": "3.8", "cabinetry": "", "vector": "", "blosc": "", "cloudpickle": "2.0.0", "distributed": "", "xrootd": "", "psutil": "", "tqdm": "", "branch": "b644bcf"}], "benchmarks": {"Q1_Parameters.Suite.TrackBytes": {"code": "class Suite:\n    def TrackBytes(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return run_data['bytesread']/run_data['walltime']\n\n    def setup(self,n):\n        class Q1Processor(processor.ProcessorABC):\n            def process(self, events):\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"met\", label=\"$E_{T}^{miss}$ [GeV]\")\n                    .Double()\n                    .fill(events.MET.pt)\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n            #executor = processor.FuturesExecutor(workers=ncores, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n            #executor = processor.FuturesExecutor(workers=ncores, status=False)\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q1Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q1_Parameters.Suite.TrackBytes", "param_names": ["Bytes per Second"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "3e603ab6c6f408e5845b872d6d68c682c5e17536103dd5b27ab3cfd782c8b20d"}, "Q1_Parameters.Suite.TrackBytesPerThread": {"code": "class Suite:\n    def TrackBytesPerThread(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return (run_data['bytesread']/run_data['walltime'])/run_data['ave_num_threads']\n\n    def setup(self,n):\n        class Q1Processor(processor.ProcessorABC):\n            def process(self, events):\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"met\", label=\"$E_{T}^{miss}$ [GeV]\")\n                    .Double()\n                    .fill(events.MET.pt)\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n            #executor = processor.FuturesExecutor(workers=ncores, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n            #executor = processor.FuturesExecutor(workers=ncores, status=False)\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q1Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q1_Parameters.Suite.TrackBytesPerThread", "param_names": ["Bytes per Thread"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "0da0eb9ad63598794d7f0b2a9bbcabeed7e95507d5eacd407f42ee779c75430a"}, "Q1_Parameters.Suite.TrackChunksize": {"code": "class Suite:\n    def TrackChunksize(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return run_data['chunksize']/run_data['walltime']\n\n    def setup(self,n):\n        class Q1Processor(processor.ProcessorABC):\n            def process(self, events):\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"met\", label=\"$E_{T}^{miss}$ [GeV]\")\n                    .Double()\n                    .fill(events.MET.pt)\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n            #executor = processor.FuturesExecutor(workers=ncores, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n            #executor = processor.FuturesExecutor(workers=ncores, status=False)\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q1Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q1_Parameters.Suite.TrackChunksize", "param_names": ["Chunksize per Second"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "8eb12c01592eed3e5a972af28573fc0cb865ca04c79270c796ad6990fef3d8de"}, "Q1_Parameters.Suite.TrackChunksizePerThread": {"code": "class Suite:\n    def TrackChunksizePerThread(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return (run_data['chunksize']/run_data['walltime'])/run_data['ave_num_threads']\n\n    def setup(self,n):\n        class Q1Processor(processor.ProcessorABC):\n            def process(self, events):\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"met\", label=\"$E_{T}^{miss}$ [GeV]\")\n                    .Double()\n                    .fill(events.MET.pt)\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n            #executor = processor.FuturesExecutor(workers=ncores, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n            #executor = processor.FuturesExecutor(workers=ncores, status=False)\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q1Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q1_Parameters.Suite.TrackChunksizePerThread", "param_names": ["Chunksize per Thread"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "0820defde121e48d76d03eafeadf99287057e1efce3782a711f93e9d069733b0"}, "Q1_Parameters.Suite.TrackThreadcount": {"code": "class Suite:\n    def TrackThreadcount(self,n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return run_data['ave_num_threads']\n\n    def setup(self,n):\n        class Q1Processor(processor.ProcessorABC):\n            def process(self, events):\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"met\", label=\"$E_{T}^{miss}$ [GeV]\")\n                    .Double()\n                    .fill(events.MET.pt)\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n            #executor = processor.FuturesExecutor(workers=ncores, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n            #executor = processor.FuturesExecutor(workers=ncores, status=False)\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q1Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q1_Parameters.Suite.TrackThreadcount", "param_names": ["Average Number of Threads"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "7055bb3ed58bc5a3fd7456a4faddaf61f1b02365761d799d03e6aee198e61adc"}, "Q1_Parameters.Suite.TrackWalltime": {"code": "class Suite:\n    def TrackWalltime(self,n):\n        with open('output.pickle', 'rb') as fd:\n                 run_data = pickle.load(fd)\n        return run_data['walltime']\n\n    def setup(self,n):\n        class Q1Processor(processor.ProcessorABC):\n            def process(self, events):\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"met\", label=\"$E_{T}^{miss}$ [GeV]\")\n                    .Double()\n                    .fill(events.MET.pt)\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n            #executor = processor.FuturesExecutor(workers=ncores, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n            #executor = processor.FuturesExecutor(workers=ncores, status=False)\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q1Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q1_Parameters.Suite.TrackWalltime", "param_names": ["Walltime"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "a2d827bb2eeb2295632022c2eb1719afb9cfaad008472571b5eac3e583ed1240"}, "Q2_Parameters.Suite.TrackBytes": {"code": "class Suite:\n    def TrackBytes(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return run_data['bytesread']/run_data['walltime']\n\n    def setup(self, n):\n        class Q2Processor(processor.ProcessorABC):\n            def process(self, events):\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"ptj\", label=\"Jet $p_{T}$ [GeV]\")\n                    .Double()\n                    .fill(ak.flatten(events.Jet.pt))\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                       schema=schemas.NanoAODSchema,\n                       savemetrics=True,\n                       chunksize=n,\n                      )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q2Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q2_Parameters.Suite.TrackBytes", "param_names": ["Bytes per Second"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "5b7ae21e35dedadc345f5c1dc51b1f7d09aa363aa5a4c9a3572c93cb225de5e1"}, "Q2_Parameters.Suite.TrackBytesPerThread": {"code": "class Suite:\n    def TrackBytesPerThread(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return (run_data['bytesread']/run_data['walltime'])/run_data['ave_num_threads']\n\n    def setup(self, n):\n        class Q2Processor(processor.ProcessorABC):\n            def process(self, events):\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"ptj\", label=\"Jet $p_{T}$ [GeV]\")\n                    .Double()\n                    .fill(ak.flatten(events.Jet.pt))\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                       schema=schemas.NanoAODSchema,\n                       savemetrics=True,\n                       chunksize=n,\n                      )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q2Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q2_Parameters.Suite.TrackBytesPerThread", "param_names": ["Bytes per Thread"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "d086c27dbd387dce3ddcfac6a8e609c17ea3c20f8f2e08c3e0665afc1a4501b5"}, "Q2_Parameters.Suite.TrackChunksize": {"code": "class Suite:\n    def TrackChunksize(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return run_data['chunksize']/run_data['walltime']\n\n    def setup(self, n):\n        class Q2Processor(processor.ProcessorABC):\n            def process(self, events):\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"ptj\", label=\"Jet $p_{T}$ [GeV]\")\n                    .Double()\n                    .fill(ak.flatten(events.Jet.pt))\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                       schema=schemas.NanoAODSchema,\n                       savemetrics=True,\n                       chunksize=n,\n                      )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q2Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q2_Parameters.Suite.TrackChunksize", "param_names": ["Chunksize per Second"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "fc3c55d0b6ea4a3eac1e08ee3a276ce76ae06cafa81453387f9deafc7553869e"}, "Q2_Parameters.Suite.TrackChunksizePerThread": {"code": "class Suite:\n    def TrackChunksizePerThread(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return (run_data['chunksize']/run_data['walltime'])/run_data['ave_num_threads']\n\n    def setup(self, n):\n        class Q2Processor(processor.ProcessorABC):\n            def process(self, events):\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"ptj\", label=\"Jet $p_{T}$ [GeV]\")\n                    .Double()\n                    .fill(ak.flatten(events.Jet.pt))\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                       schema=schemas.NanoAODSchema,\n                       savemetrics=True,\n                       chunksize=n,\n                      )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q2Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q2_Parameters.Suite.TrackChunksizePerThread", "param_names": ["Chunksize per Thread"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "1cbd960a86cb3c96b8536d47d83586f1dddf014a9d5bbe299404c6d232b92a3c"}, "Q2_Parameters.Suite.TrackThreadcount": {"code": "class Suite:\n    def TrackThreadcount(self,n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return run_data['ave_num_threads']\n\n    def setup(self, n):\n        class Q2Processor(processor.ProcessorABC):\n            def process(self, events):\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"ptj\", label=\"Jet $p_{T}$ [GeV]\")\n                    .Double()\n                    .fill(ak.flatten(events.Jet.pt))\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                       schema=schemas.NanoAODSchema,\n                       savemetrics=True,\n                       chunksize=n,\n                      )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q2Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q2_Parameters.Suite.TrackThreadcount", "param_names": ["Average Number of Threads"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "8ae8f7443531b798865b110a2fd1de404418af3187163b84abe01bb5ec10bee8"}, "Q2_Parameters.Suite.TrackWalltime": {"code": "class Suite:\n    def TrackWalltime(self,n):\n        with open('output.pickle', 'rb') as fd:\n                 run_data = pickle.load(fd)\n        return run_data['walltime']\n\n    def setup(self, n):\n        class Q2Processor(processor.ProcessorABC):\n            def process(self, events):\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"ptj\", label=\"Jet $p_{T}$ [GeV]\")\n                    .Double()\n                    .fill(ak.flatten(events.Jet.pt))\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                       schema=schemas.NanoAODSchema,\n                       savemetrics=True,\n                       chunksize=n,\n                      )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q2Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q2_Parameters.Suite.TrackWalltime", "param_names": ["Walltime"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "f253b3f32cd706869ed29cd5d2dc5b10fe9a230edf797c2625b3611c5ede04e0"}, "Q3_Parameteres.Suite.TrackBytes": {"code": "class Suite:\n    def TrackBytes(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return run_data['bytesread']/run_data['walltime']\n\n    def setup(self,n):\n        class Q3Processor(processor.ProcessorABC):\n            def process(self, events):\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"ptj\", label=\"Jet $p_{T}$ [GeV]\")\n                    .Double()\n                    .fill(ak.flatten(events.Jet[abs(events.Jet.eta) < 1].pt))\n                 )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n    \n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q3Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q3_Parameteres.Suite.TrackBytes", "param_names": ["Bytes per Second"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "09a0b8589636beffd30319094bc2bc46ecd961c99f1ae1b9a58df936ab5d8ecd"}, "Q3_Parameteres.Suite.TrackBytesPerThread": {"code": "class Suite:\n    def TrackBytesPerThread(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return (run_data['bytesread']/run_data['walltime'])/run_data['ave_num_threads']\n\n    def setup(self,n):\n        class Q3Processor(processor.ProcessorABC):\n            def process(self, events):\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"ptj\", label=\"Jet $p_{T}$ [GeV]\")\n                    .Double()\n                    .fill(ak.flatten(events.Jet[abs(events.Jet.eta) < 1].pt))\n                 )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n    \n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q3Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q3_Parameteres.Suite.TrackBytesPerThread", "param_names": ["Bytes per Thread"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "8de8eaddf3169f5d6d3905ab4661d53f0a80cf1db0e55dbe6a7edeee6f8a292a"}, "Q3_Parameteres.Suite.TrackChunksize": {"code": "class Suite:\n    def TrackChunksize(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return run_data['chunksize']/run_data['walltime']\n\n    def setup(self,n):\n        class Q3Processor(processor.ProcessorABC):\n            def process(self, events):\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"ptj\", label=\"Jet $p_{T}$ [GeV]\")\n                    .Double()\n                    .fill(ak.flatten(events.Jet[abs(events.Jet.eta) < 1].pt))\n                 )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n    \n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q3Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q3_Parameteres.Suite.TrackChunksize", "param_names": ["Chunksize per Second"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "172f6f35d3c53e3f2e1231812f04ac0d00607d683abf31fa3a4dc536bb883e74"}, "Q3_Parameteres.Suite.TrackChunksizePerThread": {"code": "class Suite:\n    def TrackChunksizePerThread(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return (run_data['chunksize']/run_data['walltime'])/run_data['ave_num_threads']\n\n    def setup(self,n):\n        class Q3Processor(processor.ProcessorABC):\n            def process(self, events):\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"ptj\", label=\"Jet $p_{T}$ [GeV]\")\n                    .Double()\n                    .fill(ak.flatten(events.Jet[abs(events.Jet.eta) < 1].pt))\n                 )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n    \n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q3Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q3_Parameteres.Suite.TrackChunksizePerThread", "param_names": ["Chunksize per Thread"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "8bc13de6a3ee01c15b79ca55c9fb8c092d3ac6437d8a8b6a4dc9978aad29f54c"}, "Q3_Parameteres.Suite.TrackThreadcount": {"code": "class Suite:\n    def TrackThreadcount(self,n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return run_data['ave_num_threads']\n\n    def setup(self,n):\n        class Q3Processor(processor.ProcessorABC):\n            def process(self, events):\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"ptj\", label=\"Jet $p_{T}$ [GeV]\")\n                    .Double()\n                    .fill(ak.flatten(events.Jet[abs(events.Jet.eta) < 1].pt))\n                 )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n    \n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q3Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q3_Parameteres.Suite.TrackThreadcount", "param_names": ["Average Number of Threads"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "8e0f86325666db66e8e0d32efb4007ce7f0b7a5922c158a3045dd5c7a772a407"}, "Q3_Parameteres.Suite.TrackWalltime": {"code": "class Suite:\n    def TrackWalltime(self,n):\n        with open('output.pickle', 'rb') as fd:\n                 run_data = pickle.load(fd)\n        return run_data['walltime']\n\n    def setup(self,n):\n        class Q3Processor(processor.ProcessorABC):\n            def process(self, events):\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"ptj\", label=\"Jet $p_{T}$ [GeV]\")\n                    .Double()\n                    .fill(ak.flatten(events.Jet[abs(events.Jet.eta) < 1].pt))\n                 )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n    \n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q3Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q3_Parameteres.Suite.TrackWalltime", "param_names": ["Walltime"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "6b37a680efd7a7ddb70f090824ff2e08a78dfcbe10e2b4ffe45fa4c8c386ceb2"}, "Q4_Parameters.Suite.TrackBytes": {"code": "class Suite:\n    def TrackBytes(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return run_data['bytesread']/run_data['walltime']\n\n    def setup(self,n):\n        class Q4Processor(processor.ProcessorABC):\n            def process(self, events):\n                has2jets = ak.sum(events.Jet.pt > 40, axis=1) >= 2\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"met\", label=\"$E_{T}^{miss}$ [GeV]\")\n                    .Double()\n                    .fill(events[has2jets].MET.pt)\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q4Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q4_Parameters.Suite.TrackBytes", "param_names": ["Bytes per Second"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "22da59cedf5ea5189aeae8d819695b8bbcfb30c19bc11c2a0fe4aad2b131c69b"}, "Q4_Parameters.Suite.TrackBytesPerThread": {"code": "class Suite:\n    def TrackBytesPerThread(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return (run_data['bytesread']/run_data['walltime'])/run_data['ave_num_threads']\n\n    def setup(self,n):\n        class Q4Processor(processor.ProcessorABC):\n            def process(self, events):\n                has2jets = ak.sum(events.Jet.pt > 40, axis=1) >= 2\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"met\", label=\"$E_{T}^{miss}$ [GeV]\")\n                    .Double()\n                    .fill(events[has2jets].MET.pt)\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q4Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q4_Parameters.Suite.TrackBytesPerThread", "param_names": ["Bytes per Thread"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "ee995f8624051624d7cb2efbfa9fb4fcfdab05e397ed837e2f1af3487cef845e"}, "Q4_Parameters.Suite.TrackChunksize": {"code": "class Suite:\n    def TrackChunksize(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return run_data['chunksize']/run_data['walltime']\n\n    def setup(self,n):\n        class Q4Processor(processor.ProcessorABC):\n            def process(self, events):\n                has2jets = ak.sum(events.Jet.pt > 40, axis=1) >= 2\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"met\", label=\"$E_{T}^{miss}$ [GeV]\")\n                    .Double()\n                    .fill(events[has2jets].MET.pt)\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q4Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q4_Parameters.Suite.TrackChunksize", "param_names": ["Chunksize per Second"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "730d87c3b1698b6285c93d6ef6efe8c2d862045613cd136943e350c057f7272b"}, "Q4_Parameters.Suite.TrackChunksizePerThread": {"code": "class Suite:\n    def TrackChunksizePerThread(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return (run_data['chunksize']/run_data['walltime'])/run_data['ave_num_threads']\n\n    def setup(self,n):\n        class Q4Processor(processor.ProcessorABC):\n            def process(self, events):\n                has2jets = ak.sum(events.Jet.pt > 40, axis=1) >= 2\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"met\", label=\"$E_{T}^{miss}$ [GeV]\")\n                    .Double()\n                    .fill(events[has2jets].MET.pt)\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q4Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q4_Parameters.Suite.TrackChunksizePerThread", "param_names": ["Chunksize per Thread"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "7adaf04adcdccb20f099a14e7a801bbd5bf77bfd20df1b0ef8df9ad12ead4e99"}, "Q4_Parameters.Suite.TrackThreadcount": {"code": "class Suite:\n    def TrackThreadcount(self,n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return run_data['ave_num_threads']\n\n    def setup(self,n):\n        class Q4Processor(processor.ProcessorABC):\n            def process(self, events):\n                has2jets = ak.sum(events.Jet.pt > 40, axis=1) >= 2\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"met\", label=\"$E_{T}^{miss}$ [GeV]\")\n                    .Double()\n                    .fill(events[has2jets].MET.pt)\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q4Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q4_Parameters.Suite.TrackThreadcount", "param_names": ["Average Number of Threads"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "377f16a2dcd813a22263a6bc44d227fa7a19298883e73cd6d634bbd0f7f8a179"}, "Q4_Parameters.Suite.TrackWalltime": {"code": "class Suite:\n    def TrackWalltime(self,n):\n        with open('output.pickle', 'rb') as fd:\n                 run_data = pickle.load(fd)\n        return run_data['walltime']\n\n    def setup(self,n):\n        class Q4Processor(processor.ProcessorABC):\n            def process(self, events):\n                has2jets = ak.sum(events.Jet.pt > 40, axis=1) >= 2\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"met\", label=\"$E_{T}^{miss}$ [GeV]\")\n                    .Double()\n                    .fill(events[has2jets].MET.pt)\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q4Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q4_Parameters.Suite.TrackWalltime", "param_names": ["Walltime"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "76a9c547de364e05238e8e5bdab53d92ff44a8392dc19fc536f55b2625e7a7b9"}, "Q5_Parameters.Suite.TrackBytes": {"code": "class Suite:\n    def TrackBytes(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return run_data['bytesread']/run_data['walltime']\n\n    def setup(self,n):\n        class Q5Processor(processor.ProcessorABC):\n            def process(self, events):\n                mupair = ak.combinations(events.Muon, 2)\n                with np.errstate(invalid=\"ignore\"):\n                    pairmass = (mupair.slot0 + mupair.slot1).mass\n                goodevent = ak.any(\n                    (pairmass > 60)\n                    & (pairmass < 120)\n                    & (mupair.slot0.charge == -mupair.slot1.charge),\n                    axis=1,\n                )\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"met\", label=\"$E_{T}^{miss}$ [GeV]\")\n                    .Double()\n                    .fill(events[goodevent].MET.pt)\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q5Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q5_Parameters.Suite.TrackBytes", "param_names": ["Bytes per Second"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "79e0053fb3fa1a0ffa94bfd73e8e6aa8979b3c83b1a272249ae9845046f96b13"}, "Q5_Parameters.Suite.TrackBytesPerThread": {"code": "class Suite:\n    def TrackBytesPerThread(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return (run_data['bytesread']/run_data['walltime'])/run_data['ave_num_threads']\n\n    def setup(self,n):\n        class Q5Processor(processor.ProcessorABC):\n            def process(self, events):\n                mupair = ak.combinations(events.Muon, 2)\n                with np.errstate(invalid=\"ignore\"):\n                    pairmass = (mupair.slot0 + mupair.slot1).mass\n                goodevent = ak.any(\n                    (pairmass > 60)\n                    & (pairmass < 120)\n                    & (mupair.slot0.charge == -mupair.slot1.charge),\n                    axis=1,\n                )\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"met\", label=\"$E_{T}^{miss}$ [GeV]\")\n                    .Double()\n                    .fill(events[goodevent].MET.pt)\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q5Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q5_Parameters.Suite.TrackBytesPerThread", "param_names": ["Bytes per Thread"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "fa0f5d522e35ba26e32249a40d5bad75a0ca306dce43f2597e9cf1f822be60f5"}, "Q5_Parameters.Suite.TrackChunksize": {"code": "class Suite:\n    def TrackChunksize(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return run_data['chunksize']/run_data['walltime']\n\n    def setup(self,n):\n        class Q5Processor(processor.ProcessorABC):\n            def process(self, events):\n                mupair = ak.combinations(events.Muon, 2)\n                with np.errstate(invalid=\"ignore\"):\n                    pairmass = (mupair.slot0 + mupair.slot1).mass\n                goodevent = ak.any(\n                    (pairmass > 60)\n                    & (pairmass < 120)\n                    & (mupair.slot0.charge == -mupair.slot1.charge),\n                    axis=1,\n                )\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"met\", label=\"$E_{T}^{miss}$ [GeV]\")\n                    .Double()\n                    .fill(events[goodevent].MET.pt)\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q5Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q5_Parameters.Suite.TrackChunksize", "param_names": ["Chunksize per Second"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "961976b13b2086f06fc0e76aaccf2c6a1b0ec9ba40e40c06dfdb62c8384ec443"}, "Q5_Parameters.Suite.TrackChunksizePerThread": {"code": "class Suite:\n    def TrackChunksizePerThread(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return (run_data['chunksize']/run_data['walltime'])/run_data['ave_num_threads']\n\n    def setup(self,n):\n        class Q5Processor(processor.ProcessorABC):\n            def process(self, events):\n                mupair = ak.combinations(events.Muon, 2)\n                with np.errstate(invalid=\"ignore\"):\n                    pairmass = (mupair.slot0 + mupair.slot1).mass\n                goodevent = ak.any(\n                    (pairmass > 60)\n                    & (pairmass < 120)\n                    & (mupair.slot0.charge == -mupair.slot1.charge),\n                    axis=1,\n                )\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"met\", label=\"$E_{T}^{miss}$ [GeV]\")\n                    .Double()\n                    .fill(events[goodevent].MET.pt)\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q5Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q5_Parameters.Suite.TrackChunksizePerThread", "param_names": ["Chunksize per Thread"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "c33195536cd87f91fb552b9f3ab4d1da2fffddaa628f02ba4f43cd41289d3eb0"}, "Q5_Parameters.Suite.TrackThreadcount": {"code": "class Suite:\n    def TrackThreadcount(self,n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return run_data['ave_num_threads']\n\n    def setup(self,n):\n        class Q5Processor(processor.ProcessorABC):\n            def process(self, events):\n                mupair = ak.combinations(events.Muon, 2)\n                with np.errstate(invalid=\"ignore\"):\n                    pairmass = (mupair.slot0 + mupair.slot1).mass\n                goodevent = ak.any(\n                    (pairmass > 60)\n                    & (pairmass < 120)\n                    & (mupair.slot0.charge == -mupair.slot1.charge),\n                    axis=1,\n                )\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"met\", label=\"$E_{T}^{miss}$ [GeV]\")\n                    .Double()\n                    .fill(events[goodevent].MET.pt)\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q5Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q5_Parameters.Suite.TrackThreadcount", "param_names": ["Average Number of Threads"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "86cc22978e2048a2796cf8600fb27284ff2a7c98ded5757026de3e264636f8e7"}, "Q5_Parameters.Suite.TrackWalltime": {"code": "class Suite:\n    def TrackWalltime(self,n):\n        with open('output.pickle', 'rb') as fd:\n                 run_data = pickle.load(fd)\n        return run_data['walltime']\n\n    def setup(self,n):\n        class Q5Processor(processor.ProcessorABC):\n            def process(self, events):\n                mupair = ak.combinations(events.Muon, 2)\n                with np.errstate(invalid=\"ignore\"):\n                    pairmass = (mupair.slot0 + mupair.slot1).mass\n                goodevent = ak.any(\n                    (pairmass > 60)\n                    & (pairmass < 120)\n                    & (mupair.slot0.charge == -mupair.slot1.charge),\n                    axis=1,\n                )\n                return (\n                    hist.Hist.new.Reg(100, 0, 200, name=\"met\", label=\"$E_{T}^{miss}$ [GeV]\")\n                    .Double()\n                    .fill(events[goodevent].MET.pt)\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q5Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q5_Parameters.Suite.TrackWalltime", "param_names": ["Walltime"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "0d345aef469b02537d8c0a3b064f06ae7d0b50ae5ae60771970f03173c578c98"}, "Q6_Parameters.Suite.TrackBytes": {"code": "class Suite:\n    def TrackBytes(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return run_data['bytesread']/run_data['walltime']\n\n    def setup(self,n):\n        class Q6Processor(processor.ProcessorABC):\n            def process(self, events):\n                jets = ak.zip(\n                    {k: getattr(events.Jet, k) for k in [\"x\", \"y\", \"z\", \"t\", \"btag\"]},\n                    with_name=\"LorentzVector\",\n                    behavior=events.Jet.behavior,\n                )\n                trijet = ak.combinations(jets, 3, fields=[\"j1\", \"j2\", \"j3\"])\n                trijet[\"p4\"] = trijet.j1 + trijet.j2 + trijet.j3\n                trijet = ak.flatten(\n                    trijet[ak.singletons(ak.argmin(abs(trijet.p4.mass - 172.5), axis=1))]\n                )\n                maxBtag = np.maximum(\n                    trijet.j1.btag,\n                    np.maximum(\n                        trijet.j2.btag,\n                        trijet.j3.btag,\n                    ),\n                )\n                return {\n                    \"trijetpt\": hist.Hist.new.Reg(\n                        100, 0, 200, name=\"pt3j\", label=\"Trijet $p_{T}$ [GeV]\"\n                    )\n                    .Double()\n                    .fill(trijet.p4.pt),\n                    \"maxbtag\": hist.Hist.new.Reg(\n                        100, 0, 1, name=\"btag\", label=\"Max jet b-tag score\"\n                    )\n                    .Double()\n                    .fill(maxBtag),\n                }\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q6Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q6_Parameters.Suite.TrackBytes", "param_names": ["Bytes per Second"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "92ae58715a4907798d1d14388aa23e65de088a8bbcc202576c478ea9647dea10"}, "Q6_Parameters.Suite.TrackBytesPerThread": {"code": "class Suite:\n    def TrackBytesPerThread(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return (run_data['bytesread']/run_data['walltime'])/run_data['ave_num_threads']\n\n    def setup(self,n):\n        class Q6Processor(processor.ProcessorABC):\n            def process(self, events):\n                jets = ak.zip(\n                    {k: getattr(events.Jet, k) for k in [\"x\", \"y\", \"z\", \"t\", \"btag\"]},\n                    with_name=\"LorentzVector\",\n                    behavior=events.Jet.behavior,\n                )\n                trijet = ak.combinations(jets, 3, fields=[\"j1\", \"j2\", \"j3\"])\n                trijet[\"p4\"] = trijet.j1 + trijet.j2 + trijet.j3\n                trijet = ak.flatten(\n                    trijet[ak.singletons(ak.argmin(abs(trijet.p4.mass - 172.5), axis=1))]\n                )\n                maxBtag = np.maximum(\n                    trijet.j1.btag,\n                    np.maximum(\n                        trijet.j2.btag,\n                        trijet.j3.btag,\n                    ),\n                )\n                return {\n                    \"trijetpt\": hist.Hist.new.Reg(\n                        100, 0, 200, name=\"pt3j\", label=\"Trijet $p_{T}$ [GeV]\"\n                    )\n                    .Double()\n                    .fill(trijet.p4.pt),\n                    \"maxbtag\": hist.Hist.new.Reg(\n                        100, 0, 1, name=\"btag\", label=\"Max jet b-tag score\"\n                    )\n                    .Double()\n                    .fill(maxBtag),\n                }\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q6Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q6_Parameters.Suite.TrackBytesPerThread", "param_names": ["Bytes per Thread"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "10a5fe0863cf7b28e755890c9c1af934319afc1c70326584afc1adfd686ac1e2"}, "Q6_Parameters.Suite.TrackChunksize": {"code": "class Suite:\n    def TrackChunksize(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return run_data['chunksize']/run_data['walltime']\n\n    def setup(self,n):\n        class Q6Processor(processor.ProcessorABC):\n            def process(self, events):\n                jets = ak.zip(\n                    {k: getattr(events.Jet, k) for k in [\"x\", \"y\", \"z\", \"t\", \"btag\"]},\n                    with_name=\"LorentzVector\",\n                    behavior=events.Jet.behavior,\n                )\n                trijet = ak.combinations(jets, 3, fields=[\"j1\", \"j2\", \"j3\"])\n                trijet[\"p4\"] = trijet.j1 + trijet.j2 + trijet.j3\n                trijet = ak.flatten(\n                    trijet[ak.singletons(ak.argmin(abs(trijet.p4.mass - 172.5), axis=1))]\n                )\n                maxBtag = np.maximum(\n                    trijet.j1.btag,\n                    np.maximum(\n                        trijet.j2.btag,\n                        trijet.j3.btag,\n                    ),\n                )\n                return {\n                    \"trijetpt\": hist.Hist.new.Reg(\n                        100, 0, 200, name=\"pt3j\", label=\"Trijet $p_{T}$ [GeV]\"\n                    )\n                    .Double()\n                    .fill(trijet.p4.pt),\n                    \"maxbtag\": hist.Hist.new.Reg(\n                        100, 0, 1, name=\"btag\", label=\"Max jet b-tag score\"\n                    )\n                    .Double()\n                    .fill(maxBtag),\n                }\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q6Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q6_Parameters.Suite.TrackChunksize", "param_names": ["Chunksize per Second"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "4847d2bf2a308342b99e778f0b46c45dd428ff826b63312edd764fb91cc1e4a8"}, "Q6_Parameters.Suite.TrackChunksizePerThread": {"code": "class Suite:\n    def TrackChunksizePerThread(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return (run_data['chunksize']/run_data['walltime'])/run_data['ave_num_threads']\n\n    def setup(self,n):\n        class Q6Processor(processor.ProcessorABC):\n            def process(self, events):\n                jets = ak.zip(\n                    {k: getattr(events.Jet, k) for k in [\"x\", \"y\", \"z\", \"t\", \"btag\"]},\n                    with_name=\"LorentzVector\",\n                    behavior=events.Jet.behavior,\n                )\n                trijet = ak.combinations(jets, 3, fields=[\"j1\", \"j2\", \"j3\"])\n                trijet[\"p4\"] = trijet.j1 + trijet.j2 + trijet.j3\n                trijet = ak.flatten(\n                    trijet[ak.singletons(ak.argmin(abs(trijet.p4.mass - 172.5), axis=1))]\n                )\n                maxBtag = np.maximum(\n                    trijet.j1.btag,\n                    np.maximum(\n                        trijet.j2.btag,\n                        trijet.j3.btag,\n                    ),\n                )\n                return {\n                    \"trijetpt\": hist.Hist.new.Reg(\n                        100, 0, 200, name=\"pt3j\", label=\"Trijet $p_{T}$ [GeV]\"\n                    )\n                    .Double()\n                    .fill(trijet.p4.pt),\n                    \"maxbtag\": hist.Hist.new.Reg(\n                        100, 0, 1, name=\"btag\", label=\"Max jet b-tag score\"\n                    )\n                    .Double()\n                    .fill(maxBtag),\n                }\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q6Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q6_Parameters.Suite.TrackChunksizePerThread", "param_names": ["Chunksize per Thread"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "1d6238f734b6f210c9ca8e4cf175eb31cb4cd0926c8138f161b88e5834965951"}, "Q6_Parameters.Suite.TrackThreadcount": {"code": "class Suite:\n    def TrackThreadcount(self,n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return run_data['ave_num_threads']\n\n    def setup(self,n):\n        class Q6Processor(processor.ProcessorABC):\n            def process(self, events):\n                jets = ak.zip(\n                    {k: getattr(events.Jet, k) for k in [\"x\", \"y\", \"z\", \"t\", \"btag\"]},\n                    with_name=\"LorentzVector\",\n                    behavior=events.Jet.behavior,\n                )\n                trijet = ak.combinations(jets, 3, fields=[\"j1\", \"j2\", \"j3\"])\n                trijet[\"p4\"] = trijet.j1 + trijet.j2 + trijet.j3\n                trijet = ak.flatten(\n                    trijet[ak.singletons(ak.argmin(abs(trijet.p4.mass - 172.5), axis=1))]\n                )\n                maxBtag = np.maximum(\n                    trijet.j1.btag,\n                    np.maximum(\n                        trijet.j2.btag,\n                        trijet.j3.btag,\n                    ),\n                )\n                return {\n                    \"trijetpt\": hist.Hist.new.Reg(\n                        100, 0, 200, name=\"pt3j\", label=\"Trijet $p_{T}$ [GeV]\"\n                    )\n                    .Double()\n                    .fill(trijet.p4.pt),\n                    \"maxbtag\": hist.Hist.new.Reg(\n                        100, 0, 1, name=\"btag\", label=\"Max jet b-tag score\"\n                    )\n                    .Double()\n                    .fill(maxBtag),\n                }\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q6Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q6_Parameters.Suite.TrackThreadcount", "param_names": ["Average Number of Threads"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "ce3889296f5a20cbf565cc83170a32791b8ea49a9e51ca80aed115b75d10d156"}, "Q6_Parameters.Suite.TrackWalltime": {"code": "class Suite:\n    def TrackWalltime(self,n):\n        with open('output.pickle', 'rb') as fd:\n                 run_data = pickle.load(fd)\n        return run_data['walltime']\n\n    def setup(self,n):\n        class Q6Processor(processor.ProcessorABC):\n            def process(self, events):\n                jets = ak.zip(\n                    {k: getattr(events.Jet, k) for k in [\"x\", \"y\", \"z\", \"t\", \"btag\"]},\n                    with_name=\"LorentzVector\",\n                    behavior=events.Jet.behavior,\n                )\n                trijet = ak.combinations(jets, 3, fields=[\"j1\", \"j2\", \"j3\"])\n                trijet[\"p4\"] = trijet.j1 + trijet.j2 + trijet.j3\n                trijet = ak.flatten(\n                    trijet[ak.singletons(ak.argmin(abs(trijet.p4.mass - 172.5), axis=1))]\n                )\n                maxBtag = np.maximum(\n                    trijet.j1.btag,\n                    np.maximum(\n                        trijet.j2.btag,\n                        trijet.j3.btag,\n                    ),\n                )\n                return {\n                    \"trijetpt\": hist.Hist.new.Reg(\n                        100, 0, 200, name=\"pt3j\", label=\"Trijet $p_{T}$ [GeV]\"\n                    )\n                    .Double()\n                    .fill(trijet.p4.pt),\n                    \"maxbtag\": hist.Hist.new.Reg(\n                        100, 0, 1, name=\"btag\", label=\"Max jet b-tag score\"\n                    )\n                    .Double()\n                    .fill(maxBtag),\n                }\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q6Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q6_Parameters.Suite.TrackWalltime", "param_names": ["Walltime"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "d7019ff99c51a2976b2ac51e09a753a5745ec970034b8aa37f61be634cc5ffd2"}, "Q7_Parameters.Suite.TrackBytes": {"code": "class Suite:\n    def TrackBytes(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return run_data['bytesread']/run_data['walltime']\n\n    def setup(self,n):\n        class Q7Processor(processor.ProcessorABC):\n            def process(self, events):\n                cleanjets = events.Jet[\n                    ak.all(\n                        events.Jet.metric_table(events.Muon[events.Muon.pt > 10]) >= 0.4, axis=2\n                    )\n                    & ak.all(\n                        events.Jet.metric_table(events.Electron[events.Electron.pt > 10]) >= 0.4,\n                        axis=2,\n                    )\n                    & (events.Jet.pt > 30)\n                ]\n                return (\n                    hist.Hist.new.Reg(\n                        100, 0, 200, name=\"sumjetpt\", label=\"Jet $\\sum p_{T}$ [GeV]\"\n                    )\n                    .Double()\n                    .fill(ak.sum(cleanjets.pt, axis=1))\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q7Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q7_Parameters.Suite.TrackBytes", "param_names": ["Bytes per Second"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "b139220678ae92baa595b85c7d692e11f96ced0cf572216ce67fcd7f9698e2a2"}, "Q7_Parameters.Suite.TrackBytesPerThread": {"code": "class Suite:\n    def TrackBytesPerThread(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return (run_data['bytesread']/run_data['walltime'])/run_data['ave_num_threads']\n\n    def setup(self,n):\n        class Q7Processor(processor.ProcessorABC):\n            def process(self, events):\n                cleanjets = events.Jet[\n                    ak.all(\n                        events.Jet.metric_table(events.Muon[events.Muon.pt > 10]) >= 0.4, axis=2\n                    )\n                    & ak.all(\n                        events.Jet.metric_table(events.Electron[events.Electron.pt > 10]) >= 0.4,\n                        axis=2,\n                    )\n                    & (events.Jet.pt > 30)\n                ]\n                return (\n                    hist.Hist.new.Reg(\n                        100, 0, 200, name=\"sumjetpt\", label=\"Jet $\\sum p_{T}$ [GeV]\"\n                    )\n                    .Double()\n                    .fill(ak.sum(cleanjets.pt, axis=1))\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q7Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q7_Parameters.Suite.TrackBytesPerThread", "param_names": ["Bytes per Thread"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "0448dc08ad6aca728ed0a18be96ead8e2ff96e8dd6206e77357311a7b2d496f0"}, "Q7_Parameters.Suite.TrackChunksize": {"code": "class Suite:\n    def TrackChunksize(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return run_data['chunksize']/run_data['walltime']\n\n    def setup(self,n):\n        class Q7Processor(processor.ProcessorABC):\n            def process(self, events):\n                cleanjets = events.Jet[\n                    ak.all(\n                        events.Jet.metric_table(events.Muon[events.Muon.pt > 10]) >= 0.4, axis=2\n                    )\n                    & ak.all(\n                        events.Jet.metric_table(events.Electron[events.Electron.pt > 10]) >= 0.4,\n                        axis=2,\n                    )\n                    & (events.Jet.pt > 30)\n                ]\n                return (\n                    hist.Hist.new.Reg(\n                        100, 0, 200, name=\"sumjetpt\", label=\"Jet $\\sum p_{T}$ [GeV]\"\n                    )\n                    .Double()\n                    .fill(ak.sum(cleanjets.pt, axis=1))\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q7Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q7_Parameters.Suite.TrackChunksize", "param_names": ["Chunksize per Second"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "95c8da7263861ae40250b06935c2900e46aab2202d4b562e6a5a5f10b624c44a"}, "Q7_Parameters.Suite.TrackChunksizePerThread": {"code": "class Suite:\n    def TrackChunksizePerThread(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return (run_data['chunksize']/run_data['walltime'])/run_data['ave_num_threads']\n\n    def setup(self,n):\n        class Q7Processor(processor.ProcessorABC):\n            def process(self, events):\n                cleanjets = events.Jet[\n                    ak.all(\n                        events.Jet.metric_table(events.Muon[events.Muon.pt > 10]) >= 0.4, axis=2\n                    )\n                    & ak.all(\n                        events.Jet.metric_table(events.Electron[events.Electron.pt > 10]) >= 0.4,\n                        axis=2,\n                    )\n                    & (events.Jet.pt > 30)\n                ]\n                return (\n                    hist.Hist.new.Reg(\n                        100, 0, 200, name=\"sumjetpt\", label=\"Jet $\\sum p_{T}$ [GeV]\"\n                    )\n                    .Double()\n                    .fill(ak.sum(cleanjets.pt, axis=1))\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q7Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q7_Parameters.Suite.TrackChunksizePerThread", "param_names": ["Chunksize per Thread"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "cd8fb88660090f0ad7b66b8835931bb7a9323fbebabbdee8214c60a439248ecd"}, "Q7_Parameters.Suite.TrackThreadcount": {"code": "class Suite:\n    def TrackThreadcount(self,n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return run_data['ave_num_threads']\n\n    def setup(self,n):\n        class Q7Processor(processor.ProcessorABC):\n            def process(self, events):\n                cleanjets = events.Jet[\n                    ak.all(\n                        events.Jet.metric_table(events.Muon[events.Muon.pt > 10]) >= 0.4, axis=2\n                    )\n                    & ak.all(\n                        events.Jet.metric_table(events.Electron[events.Electron.pt > 10]) >= 0.4,\n                        axis=2,\n                    )\n                    & (events.Jet.pt > 30)\n                ]\n                return (\n                    hist.Hist.new.Reg(\n                        100, 0, 200, name=\"sumjetpt\", label=\"Jet $\\sum p_{T}$ [GeV]\"\n                    )\n                    .Double()\n                    .fill(ak.sum(cleanjets.pt, axis=1))\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q7Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q7_Parameters.Suite.TrackThreadcount", "param_names": ["Average Number of Threads"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "5dba5dcf20dde20d0962444e77bba692fff017b2e6dbf50decc9f3beee035407"}, "Q7_Parameters.Suite.TrackWalltime": {"code": "class Suite:\n    def TrackWalltime(self,n):\n        with open('output.pickle', 'rb') as fd:\n                 run_data = pickle.load(fd)\n        return run_data['walltime']\n\n    def setup(self,n):\n        class Q7Processor(processor.ProcessorABC):\n            def process(self, events):\n                cleanjets = events.Jet[\n                    ak.all(\n                        events.Jet.metric_table(events.Muon[events.Muon.pt > 10]) >= 0.4, axis=2\n                    )\n                    & ak.all(\n                        events.Jet.metric_table(events.Electron[events.Electron.pt > 10]) >= 0.4,\n                        axis=2,\n                    )\n                    & (events.Jet.pt > 30)\n                ]\n                return (\n                    hist.Hist.new.Reg(\n                        100, 0, 200, name=\"sumjetpt\", label=\"Jet $\\sum p_{T}$ [GeV]\"\n                    )\n                    .Double()\n                    .fill(ak.sum(cleanjets.pt, axis=1))\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q7Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q7_Parameters.Suite.TrackWalltime", "param_names": ["Walltime"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "7ee1cd9d7fdf559f4c9167365fdd498d1d3dec70fd3a2ff8f8a0c33400da9382"}, "Q8_Parameters.Suite.TrackBytes": {"code": "class Suite:\n    def TrackBytes(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return run_data['bytesread']/run_data['walltime']\n\n    def setup(self,n):\n        class Q8Processor(processor.ProcessorABC):\n            def process(self, events):\n                events[\"Electron\", \"pdgId\"] = -11 * events.Electron.charge\n                events[\"Muon\", \"pdgId\"] = -13 * events.Muon.charge\n                events[\"leptons\"] = ak.concatenate(\n                    [events.Electron, events.Muon],\n                    axis=1,\n                )\n                events = events[ak.num(events.leptons) >= 3]\n                pair = ak.argcombinations(events.leptons, 2, fields=[\"l1\", \"l2\"])\n                pair = pair[(events.leptons[pair.l1].pdgId == -events.leptons[pair.l2].pdgId)]\n                with np.errstate(invalid=\"ignore\"):\n                    pair = pair[\n                        ak.singletons(\n                            ak.argmin(\n                                abs(\n                                    (events.leptons[pair.l1] + events.leptons[pair.l2]).mass\n                                    - 91.2\n                                ),\n                                axis=1,\n                            )\n                        )\n                    ]\n                events = events[ak.num(pair) > 0]\n                pair = pair[ak.num(pair) > 0][:, 0]\n                l3 = ak.local_index(events.leptons)\n                l3 = l3[(l3 != pair.l1) & (l3 != pair.l2)]\n                l3 = l3[ak.argmax(events.leptons[l3].pt, axis=1, keepdims=True)]\n                l3 = events.leptons[l3][:, 0]\n                mt = np.sqrt(2 * l3.pt * events.MET.pt * (1 - np.cos(events.MET.delta_phi(l3))))\n                return (\n                    hist.Hist.new.Reg(\n                        100, 0, 200, name=\"mt\", label=\"$\\ell$-MET transverse mass [GeV]\"\n                    )\n                    .Double()\n                    .fill(mt)\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n    \n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q8Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q8_Parameters.Suite.TrackBytes", "param_names": ["Bytes per Second"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "5c7edf34b5aab08e14772d0177ba002d91f6f2bdbb008b2f6c5ebba42c5e68e9"}, "Q8_Parameters.Suite.TrackBytesPerThread": {"code": "class Suite:\n    def TrackBytesPerThread(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return (run_data['bytesread']/run_data['walltime'])/run_data['ave_num_threads']\n\n    def setup(self,n):\n        class Q8Processor(processor.ProcessorABC):\n            def process(self, events):\n                events[\"Electron\", \"pdgId\"] = -11 * events.Electron.charge\n                events[\"Muon\", \"pdgId\"] = -13 * events.Muon.charge\n                events[\"leptons\"] = ak.concatenate(\n                    [events.Electron, events.Muon],\n                    axis=1,\n                )\n                events = events[ak.num(events.leptons) >= 3]\n                pair = ak.argcombinations(events.leptons, 2, fields=[\"l1\", \"l2\"])\n                pair = pair[(events.leptons[pair.l1].pdgId == -events.leptons[pair.l2].pdgId)]\n                with np.errstate(invalid=\"ignore\"):\n                    pair = pair[\n                        ak.singletons(\n                            ak.argmin(\n                                abs(\n                                    (events.leptons[pair.l1] + events.leptons[pair.l2]).mass\n                                    - 91.2\n                                ),\n                                axis=1,\n                            )\n                        )\n                    ]\n                events = events[ak.num(pair) > 0]\n                pair = pair[ak.num(pair) > 0][:, 0]\n                l3 = ak.local_index(events.leptons)\n                l3 = l3[(l3 != pair.l1) & (l3 != pair.l2)]\n                l3 = l3[ak.argmax(events.leptons[l3].pt, axis=1, keepdims=True)]\n                l3 = events.leptons[l3][:, 0]\n                mt = np.sqrt(2 * l3.pt * events.MET.pt * (1 - np.cos(events.MET.delta_phi(l3))))\n                return (\n                    hist.Hist.new.Reg(\n                        100, 0, 200, name=\"mt\", label=\"$\\ell$-MET transverse mass [GeV]\"\n                    )\n                    .Double()\n                    .fill(mt)\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n    \n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q8Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q8_Parameters.Suite.TrackBytesPerThread", "param_names": ["Bytes per Thread"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "aad152643bcac008dd3e88c45efa675f10341370a7888a285a0dc304d3a5dfc0"}, "Q8_Parameters.Suite.TrackChunksize": {"code": "class Suite:\n    def TrackChunksize(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return run_data['chunksize']/run_data['walltime']\n\n    def setup(self,n):\n        class Q8Processor(processor.ProcessorABC):\n            def process(self, events):\n                events[\"Electron\", \"pdgId\"] = -11 * events.Electron.charge\n                events[\"Muon\", \"pdgId\"] = -13 * events.Muon.charge\n                events[\"leptons\"] = ak.concatenate(\n                    [events.Electron, events.Muon],\n                    axis=1,\n                )\n                events = events[ak.num(events.leptons) >= 3]\n                pair = ak.argcombinations(events.leptons, 2, fields=[\"l1\", \"l2\"])\n                pair = pair[(events.leptons[pair.l1].pdgId == -events.leptons[pair.l2].pdgId)]\n                with np.errstate(invalid=\"ignore\"):\n                    pair = pair[\n                        ak.singletons(\n                            ak.argmin(\n                                abs(\n                                    (events.leptons[pair.l1] + events.leptons[pair.l2]).mass\n                                    - 91.2\n                                ),\n                                axis=1,\n                            )\n                        )\n                    ]\n                events = events[ak.num(pair) > 0]\n                pair = pair[ak.num(pair) > 0][:, 0]\n                l3 = ak.local_index(events.leptons)\n                l3 = l3[(l3 != pair.l1) & (l3 != pair.l2)]\n                l3 = l3[ak.argmax(events.leptons[l3].pt, axis=1, keepdims=True)]\n                l3 = events.leptons[l3][:, 0]\n                mt = np.sqrt(2 * l3.pt * events.MET.pt * (1 - np.cos(events.MET.delta_phi(l3))))\n                return (\n                    hist.Hist.new.Reg(\n                        100, 0, 200, name=\"mt\", label=\"$\\ell$-MET transverse mass [GeV]\"\n                    )\n                    .Double()\n                    .fill(mt)\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n    \n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q8Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q8_Parameters.Suite.TrackChunksize", "param_names": ["Chunksize per Second"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "255f99e129d3c664b85a6d56caf9b8fff3892405a7162aa232272160c6ec3bf5"}, "Q8_Parameters.Suite.TrackChunksizePerThread": {"code": "class Suite:\n    def TrackChunksizePerThread(self, n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return (run_data['chunksize']/run_data['walltime'])/run_data['ave_num_threads']\n\n    def setup(self,n):\n        class Q8Processor(processor.ProcessorABC):\n            def process(self, events):\n                events[\"Electron\", \"pdgId\"] = -11 * events.Electron.charge\n                events[\"Muon\", \"pdgId\"] = -13 * events.Muon.charge\n                events[\"leptons\"] = ak.concatenate(\n                    [events.Electron, events.Muon],\n                    axis=1,\n                )\n                events = events[ak.num(events.leptons) >= 3]\n                pair = ak.argcombinations(events.leptons, 2, fields=[\"l1\", \"l2\"])\n                pair = pair[(events.leptons[pair.l1].pdgId == -events.leptons[pair.l2].pdgId)]\n                with np.errstate(invalid=\"ignore\"):\n                    pair = pair[\n                        ak.singletons(\n                            ak.argmin(\n                                abs(\n                                    (events.leptons[pair.l1] + events.leptons[pair.l2]).mass\n                                    - 91.2\n                                ),\n                                axis=1,\n                            )\n                        )\n                    ]\n                events = events[ak.num(pair) > 0]\n                pair = pair[ak.num(pair) > 0][:, 0]\n                l3 = ak.local_index(events.leptons)\n                l3 = l3[(l3 != pair.l1) & (l3 != pair.l2)]\n                l3 = l3[ak.argmax(events.leptons[l3].pt, axis=1, keepdims=True)]\n                l3 = events.leptons[l3][:, 0]\n                mt = np.sqrt(2 * l3.pt * events.MET.pt * (1 - np.cos(events.MET.delta_phi(l3))))\n                return (\n                    hist.Hist.new.Reg(\n                        100, 0, 200, name=\"mt\", label=\"$\\ell$-MET transverse mass [GeV]\"\n                    )\n                    .Double()\n                    .fill(mt)\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n    \n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q8Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q8_Parameters.Suite.TrackChunksizePerThread", "param_names": ["Chunksize per Thread"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "a98290712a8246d43253475797e99ab66693b6e8b08d2ab282d3b0b8cda020f3"}, "Q8_Parameters.Suite.TrackThreadcount": {"code": "class Suite:\n    def TrackThreadcount(self,n):\n        with open('output.pickle', 'rb') as fd:\n            run_data = pickle.load(fd)\n        return run_data['ave_num_threads']\n\n    def setup(self,n):\n        class Q8Processor(processor.ProcessorABC):\n            def process(self, events):\n                events[\"Electron\", \"pdgId\"] = -11 * events.Electron.charge\n                events[\"Muon\", \"pdgId\"] = -13 * events.Muon.charge\n                events[\"leptons\"] = ak.concatenate(\n                    [events.Electron, events.Muon],\n                    axis=1,\n                )\n                events = events[ak.num(events.leptons) >= 3]\n                pair = ak.argcombinations(events.leptons, 2, fields=[\"l1\", \"l2\"])\n                pair = pair[(events.leptons[pair.l1].pdgId == -events.leptons[pair.l2].pdgId)]\n                with np.errstate(invalid=\"ignore\"):\n                    pair = pair[\n                        ak.singletons(\n                            ak.argmin(\n                                abs(\n                                    (events.leptons[pair.l1] + events.leptons[pair.l2]).mass\n                                    - 91.2\n                                ),\n                                axis=1,\n                            )\n                        )\n                    ]\n                events = events[ak.num(pair) > 0]\n                pair = pair[ak.num(pair) > 0][:, 0]\n                l3 = ak.local_index(events.leptons)\n                l3 = l3[(l3 != pair.l1) & (l3 != pair.l2)]\n                l3 = l3[ak.argmax(events.leptons[l3].pt, axis=1, keepdims=True)]\n                l3 = events.leptons[l3][:, 0]\n                mt = np.sqrt(2 * l3.pt * events.MET.pt * (1 - np.cos(events.MET.delta_phi(l3))))\n                return (\n                    hist.Hist.new.Reg(\n                        100, 0, 200, name=\"mt\", label=\"$\\ell$-MET transverse mass [GeV]\"\n                    )\n                    .Double()\n                    .fill(mt)\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n    \n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q8Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q8_Parameters.Suite.TrackThreadcount", "param_names": ["Average Number of Threads"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "5f93aff14298bbc0e678e1a7d671525da1a62daed29a8f1fdbc2ed19d9bf9f69"}, "Q8_Parameters.Suite.TrackWalltime": {"code": "class Suite:\n    def TrackWalltime(self,n):\n        with open('output.pickle', 'rb') as fd:\n                 run_data = pickle.load(fd)\n        return run_data['walltime']\n\n    def setup(self,n):\n        class Q8Processor(processor.ProcessorABC):\n            def process(self, events):\n                events[\"Electron\", \"pdgId\"] = -11 * events.Electron.charge\n                events[\"Muon\", \"pdgId\"] = -13 * events.Muon.charge\n                events[\"leptons\"] = ak.concatenate(\n                    [events.Electron, events.Muon],\n                    axis=1,\n                )\n                events = events[ak.num(events.leptons) >= 3]\n                pair = ak.argcombinations(events.leptons, 2, fields=[\"l1\", \"l2\"])\n                pair = pair[(events.leptons[pair.l1].pdgId == -events.leptons[pair.l2].pdgId)]\n                with np.errstate(invalid=\"ignore\"):\n                    pair = pair[\n                        ak.singletons(\n                            ak.argmin(\n                                abs(\n                                    (events.leptons[pair.l1] + events.leptons[pair.l2]).mass\n                                    - 91.2\n                                ),\n                                axis=1,\n                            )\n                        )\n                    ]\n                events = events[ak.num(pair) > 0]\n                pair = pair[ak.num(pair) > 0][:, 0]\n                l3 = ak.local_index(events.leptons)\n                l3 = l3[(l3 != pair.l1) & (l3 != pair.l2)]\n                l3 = l3[ak.argmax(events.leptons[l3].pt, axis=1, keepdims=True)]\n                l3 = events.leptons[l3][:, 0]\n                mt = np.sqrt(2 * l3.pt * events.MET.pt * (1 - np.cos(events.MET.delta_phi(l3))))\n                return (\n                    hist.Hist.new.Reg(\n                        100, 0, 200, name=\"mt\", label=\"$\\ell$-MET transverse mass [GeV]\"\n                    )\n                    .Double()\n                    .fill(mt)\n                )\n            def postprocess(self, accumulator):\n                return accumulator\n        if os.environ.get(\"LABEXTENTION_FACTORY_MODULE\") == \"coffea_casa\":\n            from dask.distributed import Client\n            client = Client(\"tls://localhost:8786\")\n            executor = processor.DaskExecutor(client=client, status=False)\n        else:\n            executor = processor.IterativeExecutor()\n    \n        run = processor.Runner(executor=executor,\n                            schema=schemas.NanoAODSchema,\n                            savemetrics=True,\n                            chunksize=n,\n                            )\n        tic = time.monotonic()\n        output, metrics = run(fileset, \"Events\", processor_instance=Q8Processor())\n        workers = len(client.scheduler_info()['workers'])\n        print('workers = ', workers, ' cores = ', 2*workers)\n        toc = time.monotonic()\n        walltime = toc - tic\n        ave_num_threads = metrics['processtime']/(toc-tic)\n        metrics['walltime']=walltime\n        metrics['ave_num_threads']=ave_num_threads\n        metrics['chunksize'] = n\n        with open('output.pickle', 'wb') as fd:\n            pickle.dump(metrics, fd, protocol=pickle.HIGHEST_PROTOCOL)\n        return fd", "name": "Q8_Parameters.Suite.TrackWalltime", "param_names": ["Walltime"], "params": [["131072", "262144", "524288"]], "timeout": 1200.0, "type": "track", "unit": "unit", "version": "7c655e95b75b6ea573d962591b633f67e0d868817bad067447749bf95e605fac"}}, "machines": {"FlatIron": {"arch": "x86_64", "cpu": "Intel(R) Xeon(R) Gold 6348 CPU @ 2.60GHz", "machine": "FlatIron", "num_cpu": "112", "os": "Linux 4.18.0-358.el8.x86_64", "ram": "527526844", "version": 1}}, "tags": {"0.0.1.dev0": 2, "0.0.1.dev1": 24, "0.0.1.dev2": 38, "0.0.1.dev7": 121, "0.0.1dev": 2, "0.1.0": 222, "ak1-nano-demo": 1640, "v0.1.0": 220, "v0.1.1": 228, "v0.1.2": 257, "v0.1.3": 259, "v0.2.0": 267, "v0.2.1": 283, "v0.2.2": 293, "v0.2.3": 299, "v0.2.4": 313, "v0.2.5": 327, "v0.3.0": 376, "v0.3.1": 396, "v0.3.2": 400, "v0.4.0": 431, "v0.4.1": 465, "v0.4.10": 641, "v0.4.11": 643, "v0.4.12": 647, "v0.4.13": 649, "v0.4.14": 655, "v0.4.15": 659, "v0.4.16": 661, "v0.4.17": 665, "v0.4.18": 667, "v0.4.19": 669, "v0.4.2": 495, "v0.4.20": 671, "v0.4.21": 673, "v0.4.22": 675, "v0.4.23": 681, "v0.4.26": 707, "v0.4.27": 709, "v0.4.3": 537, "v0.4.4": 545, "v0.4.5": 557, "v0.4.6": 569, "v0.4.7": 577, "v0.4.8": 585, "v0.4.9": 603, "v0.5.0": 711, "v0.5.1": 728, "v0.5.2": 744, "v0.5.3": 758, "v0.5.4": 786, "v0.5.5": 830, "v0.5.6": 832, "v0.5.61": 2029, "v0.5.7": 834, "v0.5.8": 842, "v0.6.0": 882, "v0.6.1": 905, "v0.6.10": 1064, "v0.6.11": 1085, "v0.6.12": 1107, "v0.6.13": 1117, "v0.6.14": 1200, "v0.6.15": 1216, "v0.6.16": 1224, "v0.6.17": 1228, "v0.6.18": 1234, "v0.6.19": 1244, "v0.6.2": 938, "v0.6.20": 1254, "v0.6.21": 1260, "v0.6.22": 1284, "v0.6.23": 1297, "v0.6.24": 1305, "v0.6.25": 1347, "v0.6.26": 1375, "v0.6.27": 1385, "v0.6.28": 1400, "v0.6.29": 1417, "v0.6.3": 971, "v0.6.30": 1418, "v0.6.31": 1422, "v0.6.32": 1439, "v0.6.33": 1471, "v0.6.34": 1482, "v0.6.35": 1492, "v0.6.36": 1501, "v0.6.37": 1519, "v0.6.38": 1546, "v0.6.39": 1551, "v0.6.4": 1001, "v0.6.40": 1604, "v0.6.41": 1641, "v0.6.42": 1647, "v0.6.43": 1680, "v0.6.44": 1701, "v0.6.45": 1746, "v0.6.46": 1774, "v0.6.47": 1809, "v0.6.48": 1843, "v0.6.49": 1880, "v0.6.5": 1019, "v0.6.50": 1911, "v0.6.51": 2029, "v0.6.6": 1033, "v0.6.7": 1042, "v0.6.8": 1048, "v0.6.9": 1053, "v0.7.0": 2032, "v0.7.0-rc.1": 1928, "v0.7.1": 2087, "v0.7.10": 2698, "v0.7.11": 2706, "v0.7.12": 2742, "v0.7.13": 2758, "v0.7.14": 2807, "v0.7.15": 2832, "v0.7.16": 2871, "v0.7.2": 2176, "v0.7.3": 2288, "v0.7.4": 2341, "v0.7.5": 2378, "v0.7.6": 2456, "v0.7.7": 2542, "v0.7.8": 2606, "v0.7.9": 2654}, "pages": [["", "Grid view", "Display as a agrid"], ["summarylist", "List view", "Display as a list"], ["regressions", "Show regressions", "Display information about recent regressions"]]}